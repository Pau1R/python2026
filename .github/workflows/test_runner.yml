name: Centralized Test Runner

on:
  workflow_call:
    secrets:
      TEACHER_PAT:
        required: true
      DEEPSEEK_API_KEY:
        required: true
      TASKS_REPO_CLASSIC_TOKEN:
        required: true

permissions:
  contents: write
  discussions: write

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 50

    steps:
      - name: Check for concurrent workflow
        id: concurrent_check
        shell: bash
        env:
          GH_TOKEN: ${{ github.token }}
          REPOSITORY: ${{ github.repository }}
          RUN_ID: ${{ github.run_id }}
        run: |
          set -euo pipefail

          OWNER="${REPOSITORY%%/*}"
          REPO="${REPOSITORY#*/}"

          URL="https://api.github.com/repos/${OWNER}/${REPO}/actions/workflows/test_runner.yml/runs?status=in_progress"
          JSON="$(curl -fsSL -H "Authorization: Bearer $GH_TOKEN" -H "Accept: application/vnd.github+json" "$URL")"

          COUNT="$(printf '%s' "$JSON" | jq --argjson current "$RUN_ID" '[.workflow_runs[] | select(.id < $current)] | length')"

          if [[ "$COUNT" -gt 0 ]]; then
            echo "skip=true" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          echo "skip=false" >> "$GITHUB_OUTPUT"

      - name: Verify starter
        id: verify_starter
        shell: python
        env:
          GITHUB_CONTEXT: ${{ toJson(github) }}
        run: |
          import json
          import os

          ctx = json.loads(os.environ.get("GITHUB_CONTEXT", "{}"))
          event = ctx.get("event") or {}

          body = ""
          if isinstance(event.get("comment"), dict) and isinstance(event["comment"].get("body"), str):
            body = event["comment"]["body"]
          elif isinstance(event.get("discussion"), dict) and isinstance(event["discussion"].get("body"), str):
            body = event["discussion"]["body"]
          elif isinstance(event.get("body"), str):
            body = event["body"]

          discussion_node_id = ""
          if isinstance(event.get("discussion"), dict) and isinstance(event["discussion"].get("node_id"), str):
            discussion_node_id = event["discussion"].get("node_id") or ""

          required = "- [x] ← нажмите и подождите 10 секунд для запуска теста"
          is_starter = "true" if required in (body or "") else "false"

          out_path = os.environ.get("GITHUB_OUTPUT")
          if not out_path:
            raise SystemExit("GITHUB_OUTPUT is not set")

          with open(out_path, "a", encoding="utf-8") as fh:
            fh.write(f"is_starter={is_starter}\n")
            fh.write(f"discussion_node_id={discussion_node_id}\n")

      - name: Checkout student repo
        if: steps.verify_starter.outputs.is_starter == 'true' && steps.concurrent_check.outputs.skip != 'true'
        uses: actions/checkout@v4
        with:
          path: student

      - name: Checkout tasks repo
        if: steps.verify_starter.outputs.is_starter == 'true' && steps.concurrent_check.outputs.skip != 'true'
        uses: actions/checkout@v4
        with:
          repository: Pau1R/python2026_tasks
          token: ${{ secrets.TEACHER_PAT }}
          path: tasks

      - name: Resolve test metadata
        id: meta
        if: steps.verify_starter.outputs.is_starter == 'true' && steps.concurrent_check.outputs.skip != 'true'
        shell: python
        env:
          DISCUSSION_NODE_ID: ${{ steps.verify_starter.outputs.discussion_node_id }}
        run: |
          import glob
          import os
          import re

          discussion_node_id = os.environ.get("DISCUSSION_NODE_ID", "").strip()
          if not discussion_node_id:
            raise SystemExit("DISCUSSION_NODE_ID is empty")

          candidates = sorted(glob.glob("student/lessons/lesson */tests/test *.md"))

          link_file = ""
          for path in candidates:
            try:
              text = open(path, encoding="utf-8").read()
            except Exception:
              continue

            if re.search(r"^discussion_node_id:\s*" + re.escape(discussion_node_id) + r"\s*$", text, flags=re.MULTILINE):
              link_file = path
              break

          if not link_file:
            raise SystemExit("Link file not found for discussion_node_id")

          text = open(link_file, encoding="utf-8").read()

          keys = [
            "test_number",
            "lesson_folder",
            "lesson_number",
            "student_short",
            "student_github",
            "discussion_node_id",
            "teacher_marker_login",
            "tracker_discussion_id",
            "tracker_comment_id",
          ]

          values = {}
          for key in keys:
            m = re.search(r"^" + re.escape(key) + r":\s*(.*?)\s*$", text, flags=re.MULTILINE)
            if m:
              values[key] = m.group(1)
            else:
              values[key] = ""

          required_nonempty = [
            "test_number",
            "lesson_folder",
            "lesson_number",
            "student_short",
            "student_github",
            "discussion_node_id",
            "tracker_discussion_id",
            "tracker_comment_id",
          ]

          missing = [k for k in required_nonempty if not (values.get(k) or "").strip()]
          if missing:
            raise SystemExit("Missing required fields: " + ", ".join(missing))

          out_path = os.environ.get("GITHUB_OUTPUT")
          if not out_path:
            raise SystemExit("GITHUB_OUTPUT is not set")

          with open(out_path, "a", encoding="utf-8") as fh:
            fh.write(f"link_file={link_file}\n")
            for key in keys:
              fh.write(f"{key}={values.get(key, '').strip()}\n")

      - name: Run test loop
        if: steps.verify_starter.outputs.is_starter == 'true' && steps.concurrent_check.outputs.skip != 'true'
        shell: python
        env:
          STUDENT_TOKEN: ${{ github.token }}
          TEACHER_PAT: ${{ secrets.TEACHER_PAT }}
          TASKS_REPO_CLASSIC_TOKEN: ${{ secrets.TASKS_REPO_CLASSIC_TOKEN }}
          DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
          DISCUSSION_NODE_ID: ${{ steps.meta.outputs.discussion_node_id }}
          TEST_NUMBER: ${{ steps.meta.outputs.test_number }}
          LESSON_FOLDER: ${{ steps.meta.outputs.lesson_folder }}
          LESSON_NUMBER: ${{ steps.meta.outputs.lesson_number }}
          STUDENT_SHORT: ${{ steps.meta.outputs.student_short }}
          STUDENT_GITHUB: ${{ steps.meta.outputs.student_github }}
          TEACHER_MARKER_LOGIN: ${{ steps.meta.outputs.teacher_marker_login }}
          TRACKER_DISCUSSION_ID: ${{ steps.meta.outputs.tracker_discussion_id }}
          TRACKER_COMMENT_ID: ${{ steps.meta.outputs.tracker_comment_id }}
          LINK_FILE: ${{ steps.meta.outputs.link_file }}
        run: |
          import base64
          import json
          import os
          import random
          import re
          import sys
          import time
          import urllib.parse
          import urllib.error
          import urllib.request



          class TimeLimitReached(Exception):
            pass


          def gh_request(method: str, url: str, token: str, headers=None, data=None, timeout=120):
            hdrs = {
              "Authorization": f"Bearer {token}",
              "Accept": "application/vnd.github+json",
            }
            if headers:
              hdrs.update(headers)

            body = None
            if data is not None:
              if isinstance(data, (bytes, bytearray)):
                body = data
              else:
                body = json.dumps(data).encode("utf-8")
                hdrs.setdefault("Content-Type", "application/json")

            req = urllib.request.Request(url, data=body, headers=hdrs, method=method)

            try:
              with urllib.request.urlopen(req, timeout=timeout) as resp:
                b = resp.read()
                status = getattr(resp, "status", 200)
                content_type = resp.headers.get("Content-Type", "")
            except urllib.error.HTTPError as exc:
              b = exc.read() if hasattr(exc, "read") else b""
              status = exc.code
              content_type = exc.headers.get("Content-Type", "") if exc.headers else ""
              raise RuntimeError(f"GitHub API error {status} for {method} {url}: {b[:500]!r}")

            if "application/json" in content_type:
              if not b:
                return status, None
              return status, json.loads(b.decode("utf-8", errors="ignore"))

            return status, b


          def gh_graphql(query: str, variables: dict, token: str):
            status, obj = gh_request(
              "POST",
              "https://api.github.com/graphql",
              token,
              data={"query": query, "variables": variables},
              timeout=120,
            )

            if not isinstance(obj, dict):
              raise RuntimeError("GraphQL: invalid response")

            if obj.get("errors"):
              raise RuntimeError(f"GraphQL errors: {obj['errors']}")

            return obj.get("data")


          student_token = os.environ.get("STUDENT_TOKEN", "")
          teacher_pat = os.environ.get("TEACHER_PAT", "")
          tasks_repo_classic_token = os.environ.get("TASKS_REPO_CLASSIC_TOKEN", "")
          deepseek_api_key = os.environ.get("DEEPSEEK_API_KEY", "")

          discussion_id = os.environ.get("DISCUSSION_NODE_ID", "").strip()
          tracker_discussion_id = os.environ.get("TRACKER_DISCUSSION_ID", "").strip()

          test_number = os.environ.get("TEST_NUMBER", "").strip()
          lesson_folder = os.environ.get("LESSON_FOLDER", "").strip()
          lesson_number = os.environ.get("LESSON_NUMBER", "").strip()

          student_short = os.environ.get("STUDENT_SHORT", "").strip()
          student_github = os.environ.get("STUDENT_GITHUB", "").strip()

          teacher_marker_login = (os.environ.get("TEACHER_MARKER_LOGIN", "") or "").strip()
          link_file_path = os.environ.get("LINK_FILE", "").strip()

          if not student_token:
            raise SystemExit("STUDENT_TOKEN is required")
          if not teacher_pat:
            raise SystemExit("TEACHER_PAT is required")
          if not tasks_repo_classic_token:
            raise SystemExit("TASKS_REPO_CLASSIC_TOKEN is required")

          if not discussion_id:
            raise SystemExit("DISCUSSION_NODE_ID is required")
          if not tracker_discussion_id:
            raise SystemExit("TRACKER_DISCUSSION_ID is required")

          if not test_number or not lesson_folder or not lesson_number:
            raise SystemExit("Test metadata is incomplete")
          if not student_short or not student_github:
            raise SystemExit("Student metadata is incomplete")


          HARD_TOTAL_SECONDS = 50 * 60
          FINISH_BUFFER_SECONDS = 120
          hard_deadline_ts = time.time() + max(0, HARD_TOTAL_SECONDS - FINISH_BUFFER_SECONDS)


          def gh_graphql_student(query: str, variables: dict):
            return gh_graphql(query, variables, student_token)


          def gh_graphql_teacher(query: str, variables: dict):
            return gh_graphql(query, variables, teacher_pat)


          def gh_graphql_classic(query: str, variables: dict):
            return gh_graphql(query, variables, tasks_repo_classic_token)


          def get_discussion():
            q = """
            query($id: ID!) {
              node(id: $id) {
                ... on Discussion {
                  id
                  number
                  title
                  url
                  body
                  comments(first: 100) {
                    nodes {
                      id
                      body
                      createdAt
                      author { login }
                    }
                  }
                }
              }
            }
            """
            data = gh_graphql_student(q, {"id": discussion_id})
            node = (data or {}).get("node")
            if not node:
              raise RuntimeError("Discussion not found")
            return node


          def update_discussion_body(target_discussion_id: str, body: str):
            q = """
            mutation($id: ID!, $body: String!) {
              updateDiscussion(input: {discussionId: $id, body: $body}) {
                discussion { id }
              }
            }
            """
            gh_graphql_classic(q, {"id": target_discussion_id, "body": body})


          def update_comment(target_comment_id: str, body: str):
            q = """
            mutation($id: ID!, $body: String!) {
              updateIssueComment(input: {id: $id, body: $body}) {
                issueComment { id }
              }
            }
            """
            gh_graphql_classic(q, {"id": target_comment_id, "body": body})


          def add_discussion_comment(target_discussion_id: str, body: str):
            q = """
            mutation($id: ID!, $body: String!) {
              addDiscussionComment(input: {discussionId: $id, body: $body}) {
                comment { id }
              }
            }
            """
            data = gh_graphql_student(q, {"id": target_discussion_id, "body": body})
            try:
              return (((data or {}).get("addDiscussionComment") or {}).get("comment") or {}).get("id")
            except Exception:
              return None


          def delete_discussion_comment(comment_id: str):
            q = """
            mutation($id: ID!) {
              deleteDiscussionComment(input: {id: $id}) {
                clientMutationId
              }
            }
            """
            gh_graphql_student(q, {"id": comment_id})


          def delete_discussion(target_discussion_id: str):
            q = """
            mutation($id: ID!) {
              deleteDiscussion(input: {id: $id}) {
                clientMutationId
              }
            }
            """
            gh_graphql_student(q, {"id": target_discussion_id})


          def get_tracker_body():
            q = """
            query($id: ID!) {
              node(id: $id) {
                ... on Discussion {
                  id
                  body
                }
              }
            }
            """
            data = gh_graphql_teacher(q, {"id": tracker_discussion_id})
            node = (data or {}).get("node")
            if not node:
              raise RuntimeError("Tracker discussion not found")
            return node.get("body") or ""


          def set_tracker_body(body: str):
            q = """
            mutation($id: ID!, $body: String!) {
              updateDiscussion(input: {discussionId: $id, body: $body}) {
                discussion { id }
              }
            }
            """
            gh_graphql_teacher(q, {"id": tracker_discussion_id, "body": body})


          def update_tracker_progress(done: int, total: int, final_percent=None, result_link=None):
            body = get_tracker_body()
            lines = body.splitlines()

            if final_percent is not None:
              if result_link:
                new_line = f"{student_short}: [{final_percent}%]({result_link})"
              else:
                new_line = f"{student_short}: {final_percent}%"
            else:
              new_line = f"{student_short}: {done}/{total}"

            out = []
            replaced = False
            for line in lines:
              if line.strip().startswith(f"{student_short}:"):
                out.append(new_line)
                replaced = True
              else:
                out.append(line)

            if not replaced:
              if out and out[-1].strip() != "":
                out.append("")
              out.append(new_line)

            set_tracker_body("\n".join(out))

          def ensure_start_checkbox_line(text: str):
            req = "- [ ] ← нажмите и подождите 10 секунд для запуска теста"
            if req not in text:
              if text and not text.endswith("\n"):
                text += "\n"
              text += req + "\n"
            return text


          def load_initial_template():
            path = "tasks/misc/inital_test_page.txt"
            try:
              template = open(path, encoding="utf-8").read()
            except Exception:
              template = ""

            if not template.strip():
              template = "- [ ] ← нажмите и подождите 10 секунд для запуска теста\n"

            template = template.replace("\r\n", "\n").replace("\r", "\n")
            template = ensure_start_checkbox_line(template)
            return template


          def is_started(body: str):
            if not body:
              return False

            if "- [x]" not in body and "- [X]" not in body:
              return False

            low = body.lower()
            if "нажмите" not in low:
              return False
            if "запуска теста" not in low:
              return False
            return True


          def normalize_checkboxes(text: str):
            if text is None:
              return ""
            t = text.replace("- [x]", "- [ ]").replace("- [X]", "- [ ]")
            return t


          def load_test_json():
            base = f"tasks/lessons/{lesson_folder}/tests"
            variant = f"{base}/test {test_number} {student_short}.json"
            common = f"{base}/test {test_number}.json"

            path = variant if os.path.exists(variant) else common
            if not os.path.exists(path):
              raise SystemExit(f"Test JSON not found: {path}")

            obj = json.loads(open(path, encoding="utf-8").read())
            if not isinstance(obj, dict):
              raise SystemExit("Test JSON must be an object")

            questions = obj.get("questions")
            if not isinstance(questions, list) or not questions:
              raise SystemExit("Test JSON must contain non-empty 'questions'")

            config = obj.get("config")
            if not isinstance(config, dict):
              config = {}

            return questions, config


          def get_question_mode(q: dict):
            qa_type = q.get("question_answer_type")
            if isinstance(qa_type, str):
              if qa_type.strip().lower() == "text":
                return "text"
              return "buttons"

            options = q.get("options")
            answers = q.get("answers")
            if options is None and answers is None:
              return "text"

            return "buttons"


          def render_buttons_page(question_text: str, options: list[str], done: int, total: int):
            perm = list(range(len(options)))
            random.shuffle(perm)
            shuffled = [options[i] for i in perm]

            lines = []
            lines.append(question_text.strip())
            lines.append("")

            for idx, opt in enumerate(shuffled, start=1):
              stripped = (opt or "").lstrip()
              if stripped.startswith("```"):
                lines.append(f"- [ ] {idx}")
                lines.append("")
                lines.append(opt.rstrip())
                lines.append("")
              else:
                lines.append(f"- [ ] {idx}. {opt}")

            lines.append(f"- [ ] 6. Я не знаю ответа")
            lines.append("")
            lines.append(f"Вопрос {done + 1}/{total}")
            lines.append("")
            lines.append("- [ ] Завершить тест досрочно")

            return "\n".join(lines).rstrip() + "\n", perm


          def render_text_page(question_text: str, done: int, total: int):
            lines = []
            lines.append(question_text.strip())
            lines.append("")
            lines.append("Ответьте на вопрос обычным комментарием.")
            lines.append("")
            lines.append(f"Вопрос {done + 1}/{total}")
            return "\n".join(lines).rstrip() + "\n"


          def parse_checked_boxes(body: str):
            selected = []
            for line in (body or "").splitlines():
              if line.lstrip().startswith("- [x]") or line.lstrip().startswith("- [X]"):
                rest = line.split("]", 1)[-1].strip()
                m = re.match(r"^(\d+)\b", rest)
                if m:
                  selected.append(int(m.group(1)))
                elif rest.startswith("Завершить тест"):
                  return "finish", None

            return "selected", selected


          def build_confirmation_page():
            return "\n".join([
              "Вы уверены что хотите завершить тест?",
              "",
              "- [ ] Да, завершить тест",
              "- [ ] Нет, продолжить тест",
              "",
            ])


          def parse_confirmation(body: str):
            for line in (body or "").splitlines():
              l = line.strip()
              if l.startswith("- [x]") or l.startswith("- [X]"):
                if "Да," in l:
                  return "yes"
                if "Нет," in l:
                  return "no"
            return None


          def cleanup_spam_comments(discussion):
            comments = (((discussion.get("comments") or {}).get("nodes")) or [])
            for idx, c in enumerate(comments):
              if idx == 0:
                continue
              author = ((c.get("author") or {}).get("login")) or ""
              if teacher_marker_login and author == teacher_marker_login:
                continue
              cid = c.get("id")
              if cid:
                try:
                  delete_discussion_comment(cid)
                except Exception:
                  pass


          def wait_for_text_answer(timeout_seconds: int):
            start = time.time()
            while time.time() - start < timeout_seconds:
              if time.time() >= hard_deadline_ts:
                raise TimeLimitReached("Hard workflow time limit reached")
              disc = get_discussion()
              comments = (((disc.get("comments") or {}).get("nodes")) or [])
              for c in reversed(comments):
                author = ((c.get("author") or {}).get("login")) or ""
                if teacher_marker_login and author == teacher_marker_login:
                  continue
                body = (c.get("body") or "").strip()
                if not body:
                  continue
                cid = c.get("id")
                return body, cid
              time.sleep(1)
            raise TimeoutError("Timeout waiting for text answer")


          def wait_for_buttons_answer(expected_template: str, timeout_seconds: int):
            start = time.time()
            while time.time() - start < timeout_seconds:
              if time.time() >= hard_deadline_ts:
                raise TimeLimitReached("Hard workflow time limit reached")
              disc = get_discussion()
              body = disc.get("body") or ""

              if normalize_checkboxes(body) != normalize_checkboxes(expected_template):
                update_discussion_body(discussion_id, expected_template)
                time.sleep(1)
                continue

              kind, selected = parse_checked_boxes(body)
              if kind == "finish":
                return "finish", None

              cleanup_spam_comments(disc)

              if selected:
                uniq = sorted(set(selected))
                if any(x < 1 or x > 6 for x in uniq):
                  update_discussion_body(discussion_id, expected_template)
                  time.sleep(1)
                  continue

                if 6 in uniq and len(uniq) > 1:
                  update_discussion_body(discussion_id, expected_template)
                  time.sleep(1)
                  continue

                return "answer", uniq

              time.sleep(1)

            raise TimeoutError("Timeout waiting for buttons answer")


          def confirm_finish(original_template: str):
            confirm_page = build_confirmation_page()
            update_discussion_body(discussion_id, confirm_page)

            start = time.time()
            while time.time() - start < 120:
              disc = get_discussion()
              decision = parse_confirmation(disc.get("body") or "")
              if decision == "yes":
                return True
              if decision == "no":
                update_discussion_body(discussion_id, original_template)
                return False
              time.sleep(1)

            update_discussion_body(discussion_id, original_template)
            return False


          def render_result_markdown(percent: int, answers_log: list[dict], ai_text: str | None):
            lines = []
            
            # Calculate total points for the whole test
            total_test_points = 0
            text_questions_points = 0
            button_questions_points = 0
            button_earned_points = 0
            
            # First pass: calculate total points
            questions, _ = load_test_json()
            for q in questions:
              q_points = q.get("max_points", 1)
              total_test_points += q_points
              if q.get("question_answer_type") == "text":
                text_questions_points += q_points
              else:
                button_questions_points += q_points
            
            # Calculate earned points from button questions
            for entry in answers_log:
              if entry.get("mode") == "buttons":
                button_earned_points += entry.get("points", 0)
            
            # Calculate percentages
            if total_test_points > 0 and button_questions_points > 0:
              # Percentage of total test points that come from button questions
              button_percentage = round((button_questions_points / total_test_points) * 100)
              # Percentage earned from button questions
              earned_percentage = round((button_earned_points / button_questions_points) * button_percentage)
              lines.append(f"Вопросы с выбором варианта: {earned_percentage}/{button_percentage}%  ")
            else:
              lines.append(f"Вопросы с выбором варианта: {percent}%  ")

            # Check if AI analysis is required
            ai_required = config.get("ai_analysis_required", False)

            for idx, entry in enumerate(answers_log, start=1):
              # Determine if answer was correct
              is_correct = False
              points = entry.get("points", 0)
              max_points = entry.get("max_points", 1)  # Default max points is 1
              
              if entry.get("mode") == "buttons":
                if points == max_points:
                  is_correct = True
                elif points > 0 and points < max_points:
                  is_correct = "partial"
                else:
                  is_correct = False
              elif entry.get("mode") == "text":
                # Text questions don't have automatic scoring
                is_correct = None
              
              status = ""
              if is_correct is True:
                status = "✅"
              elif is_correct == "partial":
                status = f"⚡ ({points}/{max_points})"
              elif is_correct is False:
                status = "❌"
              
              # Remove markdown formatting from question title
              question_text = entry.get("question", "").strip()
              # Extract title (first line) and remove markdown formatting
              title_line = question_text.split('\n')[0] if question_text else ""
              # Remove markdown headers (#, ##, etc.) and bold/italic
              title_line = title_line.lstrip('#').strip()
              title_line = title_line.replace('**', '').replace('__', '').replace('*', '').replace('_', '')
              
              lines.append(f"# {status} Вопрос {idx}. {title_line}")
              lines.append("  ")
              # Add the full question text
              lines.append(entry.get("question", "").strip())
              lines.append("  ")

              if entry.get("finished"):
                lines.append("Finished early")
                lines.append("  ")
                continue

              if entry.get("mode") == "text":
                lines.append("Answer:")
                lines.append(entry.get("answer", "").rstrip())
                lines.append("  ")
                # Add AI analysis section header if AI is required
                if ai_required:
                  lines.append("## ИИ анализ ![spinner](https://github.githubassets.com/images/spinners/octocat-spinner-32.gif)")
                  lines.append("  ")
                continue

              # Display answer options for button questions
              if entry.get("mode") == "buttons":
                lines.append("Варианты ответов:")
                selected = entry.get("selected", [])
                correct = entry.get("correct", [])
                
                # Find the matching question by comparing the text
                try:
                  questions, _ = load_test_json()
                  question_text = entry.get("question", "")
                  found_options = None
                  
                  for q in questions:
                    if q.get("question", "") == question_text:
                      found_options = q.get("options", [])
                      break
                  
                  if found_options:
                    for idx_opt, option in enumerate(found_options, start=1):
                      if idx_opt in selected:
                        lines.append(f"- [X] **Option {idx_opt}: {option}**")
                      elif idx_opt == 6 and 6 not in selected:  # Don't show "I don't know" if not selected
                        continue
                      else:
                        lines.append(f"- [ ] Option {idx_opt}: {option}")
                  else:
                    lines.append(f"Selected: {selected}")
                except Exception:
                  lines.append(f"Selected: {selected}")
                lines.append("  ")
                # Add AI analysis section header if AI is required
                if ai_required:
                  lines.append("## ИИ анализ ![spinner](https://github.githubassets.com/images/spinners/octocat-spinner-32.gif)")
                  lines.append("  ")
                continue


            if ai_text:
              lines.append("\n---\n")
              lines.append(ai_text.strip())

            return "\n".join(lines).rstrip() + "\n"


          def gh_contents_url(owner: str, repo: str, path: str):
            parts = [urllib.parse.quote(p, safe="") for p in path.split("/")]
            return f"https://api.github.com/repos/{owner}/{repo}/contents/" + "/".join(parts)


          def put_file(owner: str, repo: str, path: str, content: str, token: str, message: str):
            url = gh_contents_url(owner, repo, path)

            sha = None
            try:
              _, existing = gh_request("GET", url, token)
              if isinstance(existing, dict):
                sha = existing.get("sha")
            except Exception:
              sha = None

            payload = {
              "message": message,
              "content": base64.b64encode(content.encode("utf-8")).decode("ascii"),
              "branch": "main",
            }
            if sha:
              payload["sha"] = sha

            gh_request("PUT", url, token, data=payload)


          def delete_file(owner: str, repo: str, path: str, token: str, message: str):
            url = gh_contents_url(owner, repo, path)

            sha = None
            try:
              _, existing = gh_request("GET", url, token)
              if isinstance(existing, dict):
                sha = existing.get("sha")
            except Exception:
              sha = None

            if not sha:
              return

            payload = {
              "message": message,
              "sha": sha,
              "branch": "main",
            }

            gh_request("DELETE", url, token, data=payload)


          def build_result_link(owner: str, repo: str, path: str):
            parts = [urllib.parse.quote(p, safe="") for p in path.split("/")]
            return f"https://github.com/{owner}/{repo}/blob/main/" + "/".join(parts)


          def load_ai_prompt():
            p = "tasks/misc/test_result_analysis_prompt.md"
            try:
              text = open(p, encoding="utf-8").read()
            except Exception:
              return ""
            return text.strip()


          def call_deepseek(prompt: str):
            url = "https://api.deepseek.com/chat/completions"
            model = os.environ.get("DEEPSEEK_MODEL", "deepseek-coder")

            payload = {
              "model": model,
              "temperature": 0.1,
              "messages": [
                {"role": "system", "content": "You analyze student test answers and explain mistakes."},
                {"role": "user", "content": prompt},
              ],
            }

            req = urllib.request.Request(
              url,
              data=json.dumps(payload).encode("utf-8"),
              headers={
                "Authorization": f"Bearer {deepseek_api_key}",
                "Content-Type": "application/json",
              },
              method="POST",
            )

            try:
              with urllib.request.urlopen(req, timeout=120) as resp:
                obj = json.loads(resp.read().decode("utf-8", errors="ignore"))
            except Exception:
              return None

            choices = obj.get("choices") or []
            if not choices:
              return None

            message = choices[0].get("message") or {}
            content = (message.get("content") or "").strip()
            if content:
              return content

            return None


          questions, config = load_test_json()

          if config.get("shuffle"):
            random.shuffle(questions)

          ai_allowed = config.get("ai_analysis_required") is not False
          time_limit = None
          if "time_limit" in config:
            try:
              t = float(config.get("time_limit"))
              if t > 0:
                time_limit = t
            except Exception:
              time_limit = None

          initial_template = load_initial_template()

          start_deadline = time.time() + 15 * 60
          while time.time() < start_deadline and time.time() < hard_deadline_ts:
            disc = get_discussion()
            body = disc.get("body") or ""

            if is_started(body):
              break

            low = body.lower() if body else ""
            if "нажмите" not in low or "запуска теста" not in low:
              update_discussion_body(discussion_id, initial_template)

            time.sleep(1)

          if not is_started((get_discussion().get("body") or "")):
            raise SystemExit("Start gate timeout")

          total = len(questions)
          update_tracker_progress(0, total)

          answers_log = []
          wrong_for_ai = []

          score = 0.0
          scored_questions = 0
          max_possible_points = 0.0  # Track maximum possible points for scored questions

          started_at = time.time()
          finished_early = False

          effective_deadline_ts = hard_deadline_ts
          if time_limit is not None:
            effective_deadline_ts = min(effective_deadline_ts, started_at + time_limit)

          def enforce_deadline():
            if time.time() >= effective_deadline_ts:
              raise TimeLimitReached("Time limit reached")

          for i, q in enumerate(questions):
            if time.time() >= effective_deadline_ts:
              answers_log.append({"question": q_text, "finished": True, "reason": "time_limit", "max_points": q.get("max_points", 1)})
              finished_early = True
              break

            q_text = q.get("question") or ""
            mode = get_question_mode(q)

            if mode == "text":
              page = render_text_page(q_text, i, total)
              update_discussion_body(discussion_id, page)

              try:
                enforce_deadline()
                ans, comment_id = wait_for_text_answer(int(min(45 * 60, max(1, effective_deadline_ts - time.time()))))
              except TimeLimitReached:
                answers_log.append({"question": q_text, "finished": True, "reason": "time_limit", "max_points": q.get("max_points", 1)})
                finished_early = True
                break
              except TimeoutError:
                answers_log.append({"question": q_text, "mode": "text", "answer": "(timeout)", "score": None, "max_points": q.get("max_points", 1)})
                wrong_for_ai.append({"kind": "detailed", "question": q_text, "answer": "(timeout)"})
                update_tracker_progress(i + 1, total)
                continue

              answers_log.append({"question": q_text, "mode": "text", "answer": ans, "score": None, "max_points": q.get("max_points", 1)})
              wrong_for_ai.append({"kind": "detailed", "question": q_text, "answer": ans})

              # Update the comment to show it was accepted before deleting
              try:
                if comment_id:
                  # Update comment to show it was recorded
                  update_comment(comment_id, "Ответ засчитан ✅")
                  # Small delay to ensure the update is visible
                  time.sleep(0.5)
                  # Now delete the comment
                  delete_discussion_comment(comment_id)
              except Exception:
                pass

              update_tracker_progress(i + 1, total)
              continue

            options = q.get("options")
            answers = q.get("answers")
            if not isinstance(options, list) or len(options) != 5:
              raise SystemExit("Buttons mode question must have 5 options")
            if not isinstance(answers, list) or len(answers) != 5:
              raise SystemExit("Buttons mode question must have 5 answers")

            template, perm = render_buttons_page(q_text, options, i, total)
            update_discussion_body(discussion_id, template)

            try:
              enforce_deadline()
              kind, selected = wait_for_buttons_answer(template, int(min(45 * 60, max(1, effective_deadline_ts - time.time()))))
            except TimeLimitReached:
              answers_log.append({"question": q_text, "finished": True, "reason": "time_limit", "max_points": q.get("max_points", 1)})
              finished_early = True
              break
            except TimeoutError:
              answers_log.append({"question": q_text, "mode": "buttons", "selected": [], "points": 0.0, "correct": [], "max_points": q.get("max_points", 1), "question_id": i + 1})
              wrong_for_ai.append({"kind": "mc", "question": q_text, "selected": [], "correct": []})
              scored_questions += 1
              max_possible_points += q.get("max_points", 1)  # Add to max possible points even for timeout
              update_tracker_progress(i + 1, total)
              continue

            if kind == "finish":
              if confirm_finish(template):
                answers_log.append({"question": q_text, "finished": True, "max_points": q.get("max_points", 1)})
                finished_early = True
                break
              enforce_deadline()
              kind, selected = wait_for_buttons_answer(template, int(min(45 * 60, max(1, effective_deadline_ts - time.time()))))

            selected = selected or []

            points = 0.0
            correct_original = [idx for idx, v in enumerate(answers) if int(v) == 1]
            max_points = q.get("max_points", 1)  # Get max_points from question config, default to 1

            if selected == [6]:
              points = 0.2 * max_points  # Scale partial points by max_points
            else:
              selected_original = sorted({perm[x - 1] for x in selected if 1 <= x <= 5})
              if selected_original == sorted(correct_original):
                points = max_points  # Full points
              else:
                points = 0.0

            score += points
            scored_questions += 1
            max_possible_points += max_points  # Add to max possible points

            entry = {
              "question": q_text,
              "mode": "buttons",
              "selected": selected,
              "points": points,
              "correct": correct_original,
              "max_points": max_points,
              "question_id": i + 1,  # Store question ID (1-based)
            }
            answers_log.append(entry)

            if points < 1.0 and selected != [6]:
              wrong_for_ai.append({"kind": "mc", "question": q_text, "selected": selected, "correct": correct_original})

            update_tracker_progress(i + 1, total)

          percent = round((score / max(1, max_possible_points)) * 100)

          ai_text = None
          ai_done = False
          if ai_allowed and deepseek_api_key and deepseek_api_key.strip():
            prompt_template = load_ai_prompt()
            if prompt_template:
              payload = {
                "wrong_for_ai": wrong_for_ai,
                "answers_log": answers_log,
                "percent": percent,
                "student": student_short,
                "lesson": lesson_folder,
                "test": test_number,
              }
              prompt = prompt_template + "\n\n" + json.dumps(payload, ensure_ascii=False)
              ai_text = call_deepseek(prompt)
              if ai_text:
                ai_done = True

          result_md = render_result_markdown(percent, answers_log, ai_text)

          student_result_path = f"lessons/{lesson_folder}/tests/test {test_number} {student_short} result.md"
          tasks_result_path = student_result_path

          put_file(student_github, "python2026", student_result_path, result_md, student_token, f"Add test result {test_number} ({student_short})")
          put_file("Pau1R", "python2026_tasks", tasks_result_path, result_md, teacher_pat, f"Add test result {test_number} ({student_short})")

          result_link = build_result_link(student_github, "python2026", student_result_path)

          # Update tracker with result link immediately
          try:
            update_tracker_progress(0, total, final_percent=percent, result_link=result_link)
          except Exception:
            pass

          # Update discussion with result link immediately
          try:
            final_body = "\n".join([
              "# Тест завершен",
              "",
              f"[Результат теста]({result_link})",
              "",
              "AI-анализ выполняется..." if config.get("ai_analysis_required", False) and deepseek_api_key and deepseek_api_key.strip() else "",
              "",
            ]).rstrip() + "\n"
            update_discussion_body(discussion_id, final_body)
          except Exception:
            pass

          # Run AI analysis if required
          if config.get("ai_analysis_required", False) and deepseek_api_key and deepseek_api_key.strip():
            try:
              # Load the analysis prompt
              analysis_prompt_url = gh_contents_url("Pau1R", "python2026", "misc/test_result_analysis_prompt.md")
              _, analysis_prompt_data = gh_request("GET", analysis_prompt_url, teacher_pat)
              if analysis_prompt_data and "content" in analysis_prompt_data:
                import base64
                analysis_prompt = base64.b64decode(analysis_prompt_data["content"]).decode('utf-8')
                
                # Prepare the analysis request
                analysis_payload = {
                  "result_file": result_md,
                  "prompt": analysis_prompt
                }
                
                # Call AI for analysis
                ai_analysis_prompt = f"""Analyze the following test results using the provided prompt:

                  PROMPT:
                  {analysis_prompt}

                  TEST RESULTS:
                  {result_md}"""

                ai_analysis = call_deepseek(ai_analysis_prompt)
                
                if ai_analysis:
                  # Update result files with AI analysis
                  updated_result_md = ai_analysis.strip()
                  put_file(student_github, "python2026", student_result_path, updated_result_md, student_token, f"Update test result {test_number} ({student_short}) with AI analysis")
                  put_file("Pau1R", "python2026_tasks", tasks_result_path, updated_result_md, teacher_pat, f"Update test result {test_number} ({student_short}) with AI analysis")
                  
                  # Update the discussion to show AI analysis is complete
                  try:
                    disc = get_discussion()
                    comments = (((disc.get("comments") or {}).get("nodes")) or [])
                    for c in comments:
                      if "ИИ анализ" in c.get("body", "") and "spinner" in c.get("body", ""):
                        comment_id = c.get("id")
                        if comment_id:
                          update_comment(comment_id, "## ИИ анализ ✅")
                          break
                  except Exception:
                    pass
            except Exception as e:
              print(f"AI analysis failed: {e}")

          try:
            disc = get_discussion()
            comments = (((disc.get("comments") or {}).get("nodes")) or [])
            for c in comments:
              cid = c.get("id")
              if cid:
                try:
                  delete_discussion_comment(cid)
                except Exception:
                  pass
          except Exception:
            pass

          try:
            delete_discussion(discussion_id)
          except Exception:
            pass

          time.sleep(30 if ai_done else 10)

          link_delete_path = f"lessons/{lesson_folder}/tests/test {test_number} {student_short}.md"
          try:
            delete_file(student_github, "python2026", link_delete_path, student_token, f"Delete link file for test {test_number} ({student_short})")
          except Exception:
            pass

          try:
            delete_discussion(discussion_id)
          except Exception:
            pass

      - name: Skip non-starter
        if: steps.verify_starter.outputs.is_starter != 'true' || steps.concurrent_check.outputs.skip == 'true'
        shell: bash
        run: |
          echo "Skipped. is_starter=${{ steps.verify_starter.outputs.is_starter }}, concurrent_skip=${{ steps.concurrent_check.outputs.skip }}"
